{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhance your analyzer with labeled data\n",
    "\n",
    "\n",
    "> #################################################################################\n",
    ">\n",
    "> Note: Currently this feature is only available for analyzer scenario is `document`\n",
    ">\n",
    "> #################################################################################\n",
    "\n",
    "Labeled data is a group of samples that have been tagged with one or more labels to add context or meaning, which is used to improve analyzer's performance.\n",
    "\n",
    "Please go to [Azure AI Foundry]() to use the labling tool to annotate your data.\n",
    "\n",
    "In this notebook we will demonstrate after you have the labeled data, how to create analyzer with them and analyze your files.\n",
    "\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "1. Ensure Azure AI service is configured following [steps](../README.md#configure-azure-ai-service-resource)\n",
    "1. Follow steps in [Set labeled data](../docs/set_env_for_labeled_data.md) to add training data related env variables in `.env`.\n",
    "1. Install packages needed to run the sample\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Analyzer template\n",
    "In this sample we define a template for [purchase order](../analyzer_templates/purchase_order.json). We labeled the fields in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template = '../analyzer_templates/receipt.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure content understanding client\n",
    ">The [AzureContentUnderstandingClient](../python/content_understanding_client.py) is utility Class which contain the functions to interact with the Content Understanding server. Before Content Understanding SDK release, we can regard it as a lightweight SDK. Fill the constant **AZURE_AI_ENDPOINT**, **AZURE_AI_API_VERSION**, **AZURE_AI_API_KEY** with the information from your Azure AI Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "# import utility package from python samples root directory\n",
    "parent_dir = Path(Path.cwd()).parent\n",
    "sys.path.append(str(parent_dir))\n",
    "from python.content_understanding_client import AzureContentUnderstandingClient\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "client = AzureContentUnderstandingClient(\n",
    "    endpoint=os.getenv(\"AZURE_AI_ENDPOINT\"),\n",
    "    api_version=os.getenv(\"AZURE_AI_API_VERSION\", \"2024-12-01-preview\"),\n",
    "    token_provider=token_provider,\n",
    "    x_ms_useragent=\"azure-ai-content-understanding-python/analyzer_training\", # This header is used for sample usage telemetry, please comment out this line if you want to opt out.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create analyzer with defined schema\n",
    "Before creating the custom fields analyzer, you should fill the constant ANALYZER_ID with a business-related name. Here we randomly generate a name for demo purpose.\n",
    "\n",
    "We use **TRAINING_DATA_SAS_URL** and **TRAINING_DATA_PATH** that's set in the prerequisite step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "ANALYZER_ID = \"train-sample-\" + str(uuid.uuid4())\n",
    "\n",
    "response = client.begin_create_analyzer(\n",
    "    ANALYZER_ID,\n",
    "    analyzer_template_path=analyzer_template,\n",
    "    training_storage_container_sas_url=os.getenv(\"TRAINING_DATA_SAS_URL\"),\n",
    "    training_storage_container_path_prefix=os.getenv(\"TRAINING_DATA_PATH\"),\n",
    ")\n",
    "result = client.poll_result(response)\n",
    "if result is not None and \"status\" in result and result[\"status\"] == \"Succeeded\":\n",
    "    logging.info(f\"Here is the analyzer detail for {result['result']['analyzerId']}\")\n",
    "    logging.info(json.dumps(result, indent=2))\n",
    "else:\n",
    "    logging.info(\n",
    "        \"Check your service please, may be some issues in configuration and deployment\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use created analyzer to extract document content\n",
    "After the analyzer is successfully created, we can use it to analyze our input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.begin_analyze(ANALYZER_ID, file_location='../data/receipt.png')\n",
    "result = client.poll_result(response)\n",
    "\n",
    "logging.info(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete exist analyzer in Content Understanding Service\n",
    "This snippet is not required, but it's only used to prevent the testing analyzer from residing in your service. The custom fields analyzer could be stored in your service for reusing by subsequent business in real usage scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_analyzer(ANALYZER_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
